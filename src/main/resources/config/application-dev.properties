server.port=28080
server.http-port=8080

server.ssl.enabled=true
#指定证书
server.ssl.key-store=classpath:config/datd.keystore
server.ssl.key-store-type=JKS
#别名
server.ssl.key-alias=datdkeystore
#密码
server.ssl.key-password=datd!@#123
server.ssl.key-store-password=data!@#123
#------------------基础配置开始-------------------------------------------#
server.servlet.context-path=/datd/
custom.dnsqry.accept.port=18384
custom.udpupdate.accept.port=18394
#custom.dnsdetailqry.accept.port=18374
logging.config=classpath:config/logback-spring.xml
custom.engineschedule.cron=0 0/10 * * * ?
custom.deletelogFileschedule.cron=0 0/1 * * * ?
#------------------基础配置结束-------------------------------------------#
#------------------数据库配置开始-------------------------------------------#
custom.datasource.databaseip=10.21.41.28
custom.datasource.databaseport=3306
custom.datasource.databasename=dnsanalysis
spring.datasource.username=root
spring.datasource.password=dnscap_Dtd_337u*&$%
#------------------数据库配置结束-------------------------------------------#
#------------------redis配置开始-------------------------------------------#
spring.redis.password=aisddi123
#spring.redis.cluster.max-redirects=3
#spring.redis.cluster.nodes=10.21.17.168:4379,10.21.17.168:5379,10.21.17.168:6379
spring.redis.host=10.21.17.155
spring.redis.port=6379
#------------------redis配置结束-------------------------------------------#
#------------------kafka配置开始-------------------------------------------#
#spring.redis.password=1234
spring.kafka.enabled= false
#spring.kafka.bootstrap-servers=127.0.0.1:9092,127.0.0.1:9093,127.0.0.1:9094
spring.kafka.bootstrap-servers=10.21.17.15:9092
#每批次发送消息的数量
spring.kafka.producer.batch-size=16
#设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
spring.kafka.producer.retries=0
#producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。
spring.kafka.producer.buffer-memory= 33554432
#key序列化方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

# 消费者
spring.kafka.consumer.group-id= myGroup
spring.kafka.consumer.enable-auto-commit= true
spring.kafka.consumer.auto-commit-interval= 100ms
spring.kafka.consumer.properties.session.timeout.ms= 15000
spring.kafka.consumer.key-deserializer= org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer= org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset= earliest
#------------------kafka配置结束-------------------------------------------#
spring.datasource.url=jdbc:mysql://${custom.datasource.databaseip}:${custom.datasource.databaseport}/${custom.datasource.databasename}?useUnicode=true&characterEncoding=UTF-8&useSSL=false&allowPublicKeyRetrieval=true
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
mybatis.config-location=classpath:config/mybatis/mybatis-config.xml
mybatis.mapper-locations=classpath:config/mybatis/mapper/*.xml
#mybatis.type-aliases-package=com.ais.security.threatanalysis.mapper.pojo
spring.redis.timeout=10000
spring.redis.database=0

spring.redis.lettuce.pool.max-active=100
spring.redis.lettuce.pool.max-wait=-1
spring.redis.lettuce.pool.max-idle=8
spring.redis.lettuce.pool.min-idle=0

custom.logfile.interval=6000


custom.pythonservice.startsh=classpath:config/python_service_start.sh
custom.pythonservice.serviceport=6624
custom.pythonservice.pythonhome=/home/wangfj/pythonenv/analysis/bin/python3
custom.pythonservice.workhome=/home/wangfj/dns_analysis_server/target/analysis_server.pyc
custom.pythonservice.inihome=/home/wangfj/dns_analysis_server/target/config.ini
